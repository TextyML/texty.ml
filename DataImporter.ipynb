{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os # operation system\n",
    "from collections import namedtuple\n",
    "import json\n",
    "import plotly.offline as offline\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as pt\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from tinydb import TinyDB, Query\n",
    "crawlerPath = \"/home/retkowski/Crawler/\"\n",
    "\n",
    "class Importer():\n",
    "    def __init__(self):\n",
    "        self._NewsCollection = []\n",
    "        self._db = TinyDB('/home/retkowski/Data/newsDB.json')\n",
    "        self._News = namedtuple(\"News\",[\"title\",\"site\",\"tags\",\"text\",\"abstract\",\"url\"])\n",
    "\n",
    "    def _updateCrawler(self):\n",
    "        !cd $crawlerPath && git stash && git pull\n",
    "    \n",
    "    def _writeIntoDatabase(self):\n",
    "        path = crawlerPath+\"data\"\n",
    "        sites = [site[:-5] for site in os.listdir(path) if os.path.isfile(os.path.join(path, site)) and not site[0]== \".\"]\n",
    "        print(\"Reading sites:\", sites)\n",
    "\n",
    "        for site in sites:\n",
    "            with open(path+\"/\"+site+\".json\") as dl:\n",
    "                data = json.load(dl)\n",
    "            for link in data:\n",
    "                if link[\"tags\"] is not None:\n",
    "                    self._db.insert({'title'    : link[\"title\"],\n",
    "                               'url'      : link[\"url\"],\n",
    "                               'site'     : site,\n",
    "                               'tags'     : link[\"tags\"],\n",
    "                               'text'     : link[\"text\"],\n",
    "                               'abstract' : link[\"abstract\"]})\n",
    "    \n",
    "    def _buildDownloadList(self):\n",
    "        with open(crawlerPath + \"download-all.txt\") as dl:\n",
    "            downloadlist = json.load(dl)\n",
    "    \n",
    "        newDownloadList = []\n",
    "        for dlsite in downloadlist:\n",
    "            siteDownload = []\n",
    "            for link in dlsite[\"links\"]:\n",
    "                if db.get( where(\"url\") == link[\"url\"]) == None:\n",
    "                    siteDownload.append(link)\n",
    "            newDownloadList.append({\"name\" : dlsite[\"name\"], \"links\" : siteDownload})\n",
    "\n",
    "        with open(crawlerPath + 'download.txt', 'w') as outfile:\n",
    "            json.dump(newDownloadList, outfile)\n",
    "    \n",
    "    def _runCrawler(self):\n",
    "        self._buildDownloadList()\n",
    "        self._updateCrawler()\n",
    "        !cd $crawlerPath && ./run-crawlers.sh > \"/home/retkowski/Crawler/crawlerLog.txt\" 2>&1\n",
    "        self._writeIntoDatabase()\n",
    "        \n",
    "    def _convertIntoTupleList(self, json):\n",
    "        self._NewsCollection = []\n",
    "        for line in json:\n",
    "            self._NewsCollection.append(self._News(**line))\n",
    "    \n",
    "    def _getDataMatrix(self):\n",
    "        # Dynamically create Matrix\n",
    "        siteList = list(set([news.site for news in self._NewsCollection]))\n",
    "        tagList = list(set([tag for news in self._NewsCollection for tag in news.tags]))\n",
    "        data_matrix = [[0 for x in range(len(tagList)+2)] for y in range(len(siteList)+2)] \n",
    "\n",
    "        # Set Tag Label\n",
    "        data_matrix[0] = ['']+tagList+['Σ']\n",
    "\n",
    "        # Set Site Label\n",
    "        for siteCount, site in enumerate(siteList):\n",
    "            data_matrix[siteCount+1][0] = site\n",
    "\n",
    "        # Count Elements\n",
    "        for element in self._NewsCollection:\n",
    "            for tag in element.tags:\n",
    "                data_matrix[siteList.index(element.site)+1][tagList.index(tag)+1] += 1\n",
    "\n",
    "        # Count Sites\n",
    "        for x in range(1,len(siteList)+1):\n",
    "             data_matrix[x][len(tagList)+1] = len([news for news in self._NewsCollection if news.site == siteList[x-1]])\n",
    "\n",
    "        # Count Tags\n",
    "        sum = 0\n",
    "        for y in range(1, len(tagList)+1):\n",
    "            tempsum = len([news for news in self._NewsCollection if tagList[y-1] in news.tags])\n",
    "            data_matrix[len(siteList)+1][y] = tempsum\n",
    "            sum += tempsum\n",
    "\n",
    "        # Finishing Labeling\n",
    "        data_matrix[len(siteList)+1][0] = \"Σ\"\n",
    "        data_matrix[len(siteList)+1][len(tagList)+1] = sum\n",
    "\n",
    "        return data_matrix\n",
    "    \n",
    "    def _printMatrix(self):\n",
    "        offline.init_notebook_mode()\n",
    "        colorscale = [[0, '#bbb5b5'],[.5, '#fafafa'],[1, '#fefefe']]\n",
    "        table = FF.create_table(self._getDataMatrix(), index=True, colorscale=colorscale)\n",
    "        offline.iplot(table)\n",
    "    \n",
    "    def _importAll(self):\n",
    "        self._convertIntoTupleList(self._db.all())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
