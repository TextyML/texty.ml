{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os # operation system\n",
    "from collections import namedtuple\n",
    "import json\n",
    "import plotly.offline as offline\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as pt\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from tinydb import TinyDB, Query\n",
    "crawlerPath = \"/home/retkowski/Crawler/\"\n",
    "\n",
    "class Importer():\n",
    "    def __init__(self):\n",
    "        self._NewsCollection = []\n",
    "        self._db = TinyDB('/home/retkowski/Data/newsDB.json')\n",
    "        self._News = namedtuple(\"News\",[\"title\",\"site\",\"tags\",\"text\",\"abstract\",\"url\"])\n",
    "\n",
    "    def _updateCrawler(self):\n",
    "        #!cd $crawlerPath && git stash && git pull\n",
    "    \n",
    "    def _writeIntoDatabase(self):\n",
    "        path = crawlerPath+\"data\"\n",
    "        sites = [site[:-5] for site in os.listdir(path) if os.path.isfile(os.path.join(path, site)) and not site[0]== \".\"]\n",
    "        print(\"Reading sites:\", sites)\n",
    "\n",
    "        for site in sites:\n",
    "            with open(path+\"/\"+site+\".json\") as dl:\n",
    "                data = json.load(dl)\n",
    "            for link in data:\n",
    "                if link[\"tags\"] is not None:\n",
    "                    self._db.insert({'title'    : link[\"title\"],\n",
    "                               'url'      : link[\"url\"],\n",
    "                               'site'     : site,\n",
    "                               'tags'     : link[\"tags\"],\n",
    "                               'text'     : link[\"text\"],\n",
    "                               'abstract' : link[\"abstract\"]})\n",
    "    \n",
    "    def _buildDownloadList(self):\n",
    "        with open(crawlerPath + \"download-all.txt\") as dl:\n",
    "            downloadlist = json.load(dl)\n",
    "    \n",
    "        newDownloadList = []\n",
    "        for dlsite in downloadlist:\n",
    "            siteDownload = []\n",
    "            for link in dlsite[\"links\"]:\n",
    "                if db.get( where(\"url\") == link[\"url\"]) == None:\n",
    "                    siteDownload.append(link)\n",
    "            newDownloadList.append({\"name\" : dlsite[\"name\"], \"links\" : siteDownload})\n",
    "\n",
    "        with open(crawlerPath + 'download.txt', 'w') as outfile:\n",
    "            json.dump(newDownloadList, outfile)\n",
    "    \n",
    "    def _runCrawler(self):\n",
    "        self._buildDownloadList()\n",
    "        self._updateCrawler()\n",
    "        !cd $crawlerPath && ./run-crawlers.sh > \"/home/retkowski/Crawler/crawlerLog.txt\" 2>&1\n",
    "        self._writeIntoDatabase()\n",
    "        \n",
    "    def _convertIntoTupleList(self, json):\n",
    "        self._NewsCollection = []\n",
    "        for line in json:\n",
    "            self._NewsCollection.append(self._News(**line))\n",
    "    \n",
    "    def _getDataMatrix(self):\n",
    "        # Dynamically create Matrix\n",
    "        siteList = list(set([news.site for news in self._NewsCollection]))\n",
    "        tagList = list(set([tag for news in self._NewsCollection for tag in news.tags]))\n",
    "        data_matrix = [[0 for x in range(len(tagList)+2)] for y in range(len(siteList)+2)] \n",
    "\n",
    "        # Set Tag Label\n",
    "        data_matrix[0] = ['']+tagList+['Σ']\n",
    "\n",
    "        # Set Site Label\n",
    "        for siteCount, site in enumerate(siteList):\n",
    "            data_matrix[siteCount+1][0] = site\n",
    "\n",
    "        # Count Elements\n",
    "        for element in self._NewsCollection:\n",
    "            for tag in element.tags:\n",
    "                data_matrix[siteList.index(element.site)+1][tagList.index(tag)+1] += 1\n",
    "\n",
    "        # Count Sites\n",
    "        for x in range(1,len(siteList)+1):\n",
    "             data_matrix[x][len(tagList)+1] = len([news for news in self._NewsCollection if news.site == siteList[x-1]])\n",
    "\n",
    "        # Count Tags\n",
    "        sum = 0\n",
    "        for y in range(1, len(tagList)+1):\n",
    "            tempsum = len([news for news in self._NewsCollection if tagList[y-1] in news.tags])\n",
    "            data_matrix[len(siteList)+1][y] = tempsum\n",
    "            sum += tempsum\n",
    "\n",
    "        # Finishing Labeling\n",
    "        data_matrix[len(siteList)+1][0] = \"Σ\"\n",
    "        data_matrix[len(siteList)+1][len(tagList)+1] = sum\n",
    "\n",
    "        return data_matrix\n",
    "    \n",
    "    def _printMatrix(self):\n",
    "        offline.init_notebook_mode()\n",
    "        colorscale = [[0, '#bbb5b5'],[.5, '#fafafa'],[1, '#fefefe']]\n",
    "        table = FF.create_table(self._getDataMatrix(), index=True, colorscale=colorscale)\n",
    "        offline.iplot(table)\n",
    "    \n",
    "    def _importAll(self):\n",
    "        self._convertIntoTupleList(self._db.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run \"Import/DataImporter.py\"\n",
    "importer = DataImporter(path='/home/retkowski/Private/newsDB.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (CorpusImporter.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/home/retkowski/texty-ml/Import/CorpusImporter.py\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    def crawlNYT(self, no_text, to_database, is_multilabel, ):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "%run \"Import/CorpusImporter.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importer._removeAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading archives: ['04.tgz', '05.tgz', '03.tgz', '06.tgz', '01.tgz', '02.tgz']\n"
     ]
    }
   ],
   "source": [
    "importer._crawlNYTintoDB(no_text=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importer._importAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22386\n"
     ]
    }
   ],
   "source": [
    "print(len(importer._NewsCollection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of documents: 39953\n"
     ]
    }
   ],
   "source": [
    "# NYT Corpus\n",
    "import tarfile,os\n",
    "import sys\n",
    "from contextlib import closing\n",
    "\n",
    "nyt_path = \"/home/retkowski/nltk_data/nyt/data/2007\"\n",
    "archives = [archive for archive in os.listdir(nyt_path) if os.path.isfile(os.path.join(nyt_path, archive)) and not archive[0]== \".\"]\n",
    "count_doc = 0\n",
    "for archive in archives:\n",
    "    with tarfile.open(nyt_path+\"/\"+archive) as afile:\n",
    "        for member in afile:\n",
    "            if member.isreg() and member.name.endswith('.xml'): \n",
    "                count_doc +=1\n",
    "\n",
    "        \n",
    "print(\"Amount of documents: \"+ str(count_doc))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
