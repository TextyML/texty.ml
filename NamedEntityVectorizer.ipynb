{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from Import.NamedEntityVectorizer import NamedEntityVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Donald Trump' 'Hillary Clinton' 'Fabian Retkowski' 'Hillary Trump']\n",
      "[array([ 0.11111111,  0.        ,  0.        ,  0.11111111]), array([ 0.08333333,  0.        ,  0.08333333,  0.        ]), array([ 0.        ,  0.16666667,  0.        ,  0.        ])]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "del sys.modules['Import.NamedEntityVectorizer']\n",
    "from Import.NamedEntityVectorizer import NamedEntityVectorizer\n",
    "nerv = NamedEntityVectorizer(entity=\"PERSON\",max_features=4)\n",
    "\n",
    "texts = [\"Donald Trump is made by Hillary Trump in London\", \"America's Fabian Retkowski is a person made by Donald Trump.\", \"Hillary Clinton is not a person, but Hillary Clinton is.\"]\n",
    "            \n",
    "nerv.fit(texts)\n",
    "print(nerv.get_feature_names())\n",
    "print(nerv.transform(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PERSON', 'Donald'], ['PERSON', 'Trump'], ['O', 'is'], ['O', 'made'], ['O', 'by'], ['PERSON', 'Hillary'], ['PERSON', 'Trump'], ['O', 'in']]\n"
     ]
    }
   ],
   "source": [
    "tagged = nerv._stanford_tagger(text=\"Donald Trump is made by Hillary Trump in London\")\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Donald', 'Trump', 'Hillary', 'Trump']\n",
      "['Hillary', 'Trump', 'Donald']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'build_doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e3ac4df0c5f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mbuild_doc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mdoc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_doc' is not defined"
     ]
    }
   ],
   "source": [
    "list_of = [chunk[1] for chunk in tagged if chunk[0] == \"PERSON\"]\n",
    "list_set_of = list(set(list_of))\n",
    "print(list_of)\n",
    "print(list_set_of)\n",
    "for feature in list_of:\n",
    "    try:\n",
    "        if build_doc:\n",
    "            doc_dict[feature] += 1\n",
    "            vocabulary[feature] += 1\n",
    "    except KeyError:\n",
    "        vocabulary[feature] = 1\n",
    "                    \n",
    "    for feature in list_set_of:\n",
    "        try:\n",
    "            counter[feature] += 1\n",
    "        except KeyError:\n",
    "            counter[feature] = 1\n",
    "\n",
    "print(list_of)\n",
    "print(list_set_of)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Hillary Trump | Donald Trump | Fabian Retkowski | Hillary Clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[array([], dtype=float64), array([], dtype=float64)]\n"
     ]
    }
   ],
   "source": [
    "nerv = NamedEntityVectorizer(entity=\"PERSON\",max_features=5)\n",
    "texts = [\"Max is sexy\", \"Aram is not sexy\"]\n",
    "nerv.fit(texts)\n",
    "print(nerv.get_feature_names())\n",
    "print(nerv.transform(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[array([], dtype=float64)]\n"
     ]
    }
   ],
   "source": [
    "nerv = NamedEntityVectorizer(entity=\"PERSON\",max_features=4)\n",
    "texts = [\"ewe\"]\n",
    "nerv.fit(texts)\n",
    "print(nerv.get_feature_names())\n",
    "print(nerv.transform(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bulls', 'Raptors', 'Nets', 'Continental Arena', 'Phoenix Suns', 'Toronto Raptors', 'Cavaliers', 'Atlantic Division']\n"
     ]
    }
   ],
   "source": [
    "tagged = [['Nets', 'ORGANIZATION'], ['Atlantic Division', 'ORGANIZATION'], ['Vince Carter', 'PERSON'], ['Toronto Raptors', 'ORGANIZATION'], ['Continental Arena', 'ORGANIZATION'], ['Jason Kidd', 'PERSON'], ['Kidd', 'PERSON'], ['Joumana', 'PERSON'], ['Nets', 'ORGANIZATION'], ['Raptors', 'ORGANIZATION'], ['Atlantic Division', 'ORGANIZATION'], ['Raptors', 'ORGANIZATION'], ['Carter', 'PERSON'], ['Toronto', 'LOCATION'], ['Raptors', 'ORGANIZATION'], ['Phoenix Suns', 'ORGANIZATION'], ['Andrea Bargnani', 'PERSON'], ['Raptors', 'ORGANIZATION'], ['Bargnani', 'PERSON'], ['Nets', 'ORGANIZATION'], ['Chris Bosh', 'PERSON'], ['Raptors', 'ORGANIZATION'], ['\\nBosh', 'PERSON'], ['Toronto', 'LOCATION'], ['T. J. Ford', 'PERSON'], ['Mikki Moore', 'PERSON'], ['Bosh', 'PERSON'], ['Nets', 'ORGANIZATION'], ['Raptors', 'ORGANIZATION'], ['Nets', 'ORGANIZATION'], ['Raptors', 'ORGANIZATION'], ['Nets', 'ORGANIZATION'], ['Nets', 'ORGANIZATION'], ['Bargnani', 'PERSON'], ['Richard Jefferson', 'PERSON'], ['\\nCarter', 'PERSON'], ['Nets', 'ORGANIZATION'], ['Raptors', 'ORGANIZATION'], ['Toronto', 'LOCATION'], ['Carter', 'PERSON'], ['Carter', 'PERSON'], ['Cliff Robinson', 'PERSON'], ['Carter', 'PERSON'], ['Robinson', 'PERSON'], ['Nets', 'ORGANIZATION'], ['Cavaliers', 'ORGANIZATION'], ['Cleveland', 'LOCATION'], ['Carter', 'PERSON'], ['Cliff Robinson', 'PERSON'], ['\\nRobinson', 'PERSON'], ['Bulls', 'ORGANIZATION'], ['Nets', 'ORGANIZATION'], ['Josh Boone', 'PERSON']]\n",
    "list_of = [chunk[0] for chunk in tagged if chunk[1] == \"ORGANIZATION\"]\n",
    "list_set_of = list(set(list_of))\n",
    "print(list_set_of)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
